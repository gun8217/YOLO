{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8znEfIJjQ4L"
   },
   "source": [
    "# SimpleCNN + Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3eEsshnVjAz3"
   },
   "outputs": [],
   "source": [
    "# 사용자 정의 Dataset 클래스 추가\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map  # 예: {'cat': 0, 'dog': 1}\n",
    "\n",
    "        for class_name, label in label_map.items():\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            for fname in os.listdir(class_path):\n",
    "                if fname.lower().endswith(('.jpg', '.png')):\n",
    "                    self.samples.append((os.path.join(class_path, fname), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 381749,
     "status": "ok",
     "timestamp": 1752893537432,
     "user": {
      "displayName": "charlie whisky",
      "userId": "06471801880864215670"
     },
     "user_tz": -540
    },
    "id": "O9rtN25xj4RL",
    "outputId": "a77880d7-3b85-45b1-c0fe-afe3a1daaa15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE= cpu\n",
      "[✅] GOOD 클래스 - 이미지 수: 527\n",
      "[✅] BAD 클래스 - 이미지 수: 550\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 1. 하이퍼파라미터 및 설정\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE=\", DEVICE)\n",
    "\n",
    "# 2. 데이터 전처리\n",
    "# 이미지를 전처리(Preprocessing) 하기 위한 연속된 변환 작업(transform pipeline) 을 정의\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),      # 이미지를 고정 크기로 설정\n",
    "    transforms.ToTensor(),              # 이미지를 PyTorch 텐서로 변환\n",
    "    transforms.Normalize([0.5], [0.5])  # 빠르고 안정적인 학습을 위한 정규화(0~1 -> -1~1), (x-0.5)/0.5\n",
    "])\n",
    "data_path = \"C:/Users/602-18/YOLO/Learning/class/before/dataset/carrot\"\n",
    "classes = ['GOOD', 'BAD']\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(data_path, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"[❌] 디렉토리 없음: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(class_dir)\n",
    "              if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(image_extensions)]\n",
    "\n",
    "    print(f\"[✅] {cls} 클래스 - 이미지 수: {len(images)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 클래스 목록\n",
    "classes = ['GOOD', 'BAD']\n",
    "\n",
    "# 분할 저장 경로\n",
    "dest_root = 'C:/Users/602-18/YOLO/Learning/class/before/dataset_split/carrot'\n",
    "\n",
    "# # 4. 분할 비율\n",
    "# split_ratio = [0.8, 0.19, 0.01]\n",
    "# splits = ['train', 'val', 'test']\n",
    "\n",
    "# # 5. 대상 폴더 구조 생성: .../carrot/train/GOOD 등\n",
    "# for split in splits:\n",
    "#     for cls in classes:\n",
    "#         split_cls_dir = os.path.join(dest_root, split, cls)\n",
    "#         os.makedirs(split_cls_dir, exist_ok=True)\n",
    "\n",
    "# # 6. 이미지 분할 및 복사\n",
    "# for cls in classes:\n",
    "#     src_dir = os.path.join(data_path, cls)\n",
    "#     if not os.path.isdir(src_dir):\n",
    "#         print(f\"[❌] 디렉토리 없음: {src_dir}\")\n",
    "#         continue\n",
    "\n",
    "#     images = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "#     random.shuffle(images)\n",
    "\n",
    "#     total = len(images)\n",
    "#     train_end = int(split_ratio[0] * total)\n",
    "#     val_end = train_end + int(split_ratio[1] * total)\n",
    "\n",
    "#     split_files = {\n",
    "#         'train': images[:train_end],\n",
    "#         'val': images[train_end:val_end],\n",
    "#         'test': images[val_end:]\n",
    "#     }\n",
    "\n",
    "#     for split, file_list in split_files.items():\n",
    "#         for img in file_list:\n",
    "#             src = os.path.join(src_dir, img)\n",
    "#             dst = os.path.join(dest_root, split, cls, img)\n",
    "#             os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "#             shutil.copy(src, dst)\n",
    "\n",
    "# print(\"✅ 이미지 분할 및 복사가 완료되었습니다.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[📁] 클래스: GOOD | 이미지 수: 100\n",
      "[📁] 클래스: BAD | 이미지 수: 104\n",
      "✅ val 이미지에 대한 증강 완료 및 저장됨.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "val_dir = 'C:/Users/602-18/YOLO/Learning/class/before/dataset_split/carrot/val'\n",
    "\n",
    "num_aug_per_image = 2\n",
    "def augment_image(image):\n",
    "    if random.random() > 0.5:\n",
    "        image = F.hflip(image)                           # 반전\n",
    "    if random.random() > 0.5:\n",
    "        angle = random.uniform(-30, 30)\n",
    "        image = F.rotate(image, angle)                   # 회전\n",
    "    if random.random() > 0.5:\n",
    "        brightness = random.uniform(0.7, 1.3)\n",
    "        contrast = random.uniform(0.7, 1.3)\n",
    "        image = F.adjust_brightness(image, brightness)   # 밝기 조절\n",
    "        image = F.adjust_contrast(image, contrast)       # 명암 조절\n",
    "    return image\n",
    "\n",
    "# 이미지 확장자\n",
    "image_exts = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(val_dir, cls)\n",
    "    images = [f for f in os.listdir(class_dir) if f.lower().endswith(image_exts)]\n",
    "\n",
    "    print(f\"[📁] 클래스: {cls} | 이미지 수: {len(images)}\")\n",
    "\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[⚠️] 이미지 열기 실패: {img_path}, 에러: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i in range(num_aug_per_image):\n",
    "            aug_img = augment_image(image)\n",
    "            base, ext = os.path.splitext(img_name)\n",
    "            new_filename = f\"aug_{base}_{i}{ext}\"\n",
    "            new_path = os.path.join(class_dir, new_filename)\n",
    "            aug_img.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, stddev=50):\n",
    "    arr = np.array(img).astype(np.float32)\n",
    "    noise = np.random.normal(0, stddev, arr.shape)\n",
    "    noisy_arr = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_arr)\n",
    "\n",
    "def apply_affine(img):\n",
    "    width, height = img.size\n",
    "    coeffs = (1, 0.2, -10,   # a, b, c\n",
    "              0.1, 1, -5)    # d, e, f\n",
    "    return img.transform((width, height), Image.AFFINE, coeffs, resample=Image.BICUBIC)\n",
    "\n",
    "def apply_rotation(img, angle=4):\n",
    "    return img.rotate(angle, resample=Image.BICUBIC, expand=True).crop((0, 0, img.size[0], img.size[1]))\n",
    "\n",
    "def apply_random_crop_resize(img, crop_ratio=0.9):\n",
    "    w, h = img.size\n",
    "    crop_w, crop_h = int(w * crop_ratio), int(h * crop_ratio)\n",
    "    left = np.random.randint(0, w - crop_w + 1)\n",
    "    top = np.random.randint(0, h - crop_h + 1)\n",
    "    cropped = img.crop((left, top, left + crop_w, top + crop_h))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map 정의\n",
    "label_map = {'BAD': 0, 'GOOD': 1}\n",
    "class_names = list(label_map.keys())\n",
    "\n",
    "# 커스텀 Dataset 적용\n",
    "train_dataset = CustomImageDataset(root_dir=dest_root+'/train', label_map=label_map, transform=transform)\n",
    "valid_dataset = CustomImageDataset(root_dir=dest_root+'/val', label_map=label_map, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)  # 모델이 순서에 영향을 받지 않도록 매 epoch마다 무작위로 섞는다\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False) # 데이터 순서 고정\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EhAo7ZPSkY3y"
   },
   "outputs": [],
   "source": [
    "# 3. 모델 정의\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # nn.Conv2d(3채널(RGB), 필터수, 필터크기, stride=1, padding=0)\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # 128x128x3 -> 128x128x16, padding=1은 1픽셀 추가하여 출력크기 유지\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # -> 64x64x16, 이미지 크기를 1/2로 축소(국소적 특징 요약)\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # -> 32x32x32\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 224),  # 입력은 CNN에서 전달된 크기, 출력은 보통 64, 128, 256, 512 등\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(224, 2)   # 최종 출력이 1이면 Sigmoid연결, 2이면 Softmax연결\n",
    "            # BCEWithLogitsLoss() (또는 BCELoss + Sigmoid),\tCrossEntropyLoss() (Softmax 포함)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()  # Softmax 포함\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 10.8846 | Train Acc: 0.9837 | Val Acc: 0.8284 | Time: 41.50 sec\n",
      "Epoch 2 | Loss: 0.0040 | Train Acc: 1.0000 | Val Acc: 0.8301 | Time: 41.53 sec\n",
      "Epoch 3 | Loss: 0.0008 | Train Acc: 1.0000 | Val Acc: 0.8268 | Time: 42.23 sec\n",
      "Epoch 4 | Loss: 0.0004 | Train Acc: 1.0000 | Val Acc: 0.8235 | Time: 43.20 sec\n",
      "Epoch 5 | Loss: 0.0002 | Train Acc: 1.0000 | Val Acc: 0.8235 | Time: 42.62 sec\n",
      "Epoch 6 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8219 | Time: 42.57 sec\n",
      "Epoch 7 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8186 | Time: 42.98 sec\n",
      "Epoch 8 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8154 | Time: 42.69 sec\n",
      "Epoch 9 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8121 | Time: 42.43 sec\n",
      "Epoch 10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8088 | Time: 43.85 sec\n",
      "Epoch 11 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8072 | Time: 43.45 sec\n",
      "Epoch 12 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8072 | Time: 43.43 sec\n",
      "Epoch 13 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8039 | Time: 42.80 sec\n",
      "Epoch 14 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8056 | Time: 42.73 sec\n",
      "Epoch 15 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 42.78 sec\n",
      "Epoch 16 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 43.22 sec\n",
      "Epoch 17 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 43.19 sec\n",
      "Epoch 18 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8007 | Time: 42.91 sec\n",
      "Epoch 19 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 42.40 sec\n",
      "Epoch 20 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7974 | Time: 44.43 sec\n",
      "Epoch 21 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7941 | Time: 43.61 sec\n",
      "Epoch 22 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.07 sec\n",
      "Epoch 23 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.38 sec\n",
      "Epoch 24 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.35 sec\n",
      "Epoch 25 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7876 | Time: 43.30 sec\n",
      "Epoch 26 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7859 | Time: 42.57 sec\n",
      "Epoch 27 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7810 | Time: 43.00 sec\n",
      "Epoch 28 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7827 | Time: 42.05 sec\n",
      "Epoch 29 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7810 | Time: 42.33 sec\n",
      "Epoch 30 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7778 | Time: 42.10 sec\n",
      "Epoch 31 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7778 | Time: 42.86 sec\n",
      "Epoch 32 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7745 | Time: 42.70 sec\n",
      "Epoch 33 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7729 | Time: 42.66 sec\n",
      "Epoch 34 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7647 | Time: 42.97 sec\n",
      "Epoch 35 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7614 | Time: 42.32 sec\n",
      "Epoch 36 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7582 | Time: 42.45 sec\n",
      "Epoch 37 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7565 | Time: 42.48 sec\n",
      "Epoch 38 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7549 | Time: 43.20 sec\n",
      "Epoch 39 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7549 | Time: 44.07 sec\n",
      "Epoch 40 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7516 | Time: 42.17 sec\n",
      "Epoch 41 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7516 | Time: 42.53 sec\n",
      "Epoch 42 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7500 | Time: 45.50 sec\n",
      "Epoch 43 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7484 | Time: 43.58 sec\n",
      "Epoch 44 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 42.47 sec\n",
      "Epoch 45 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 42.18 sec\n",
      "Epoch 46 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 43.18 sec\n",
      "Epoch 47 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7418 | Time: 43.35 sec\n",
      "Epoch 48 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7418 | Time: 42.25 sec\n",
      "Epoch 49 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.18 sec\n",
      "Epoch 50 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.16 sec\n",
      "Epoch 51 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.82 sec\n",
      "Epoch 52 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.15 sec\n",
      "Epoch 53 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.90 sec\n",
      "Epoch 54 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.70 sec\n",
      "Epoch 55 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.60 sec\n",
      "Epoch 56 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.18 sec\n",
      "Epoch 57 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.15 sec\n",
      "Epoch 58 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7337 | Time: 42.50 sec\n",
      "Epoch 59 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.65 sec\n",
      "Epoch 60 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.63 sec\n",
      "Epoch 61 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 42.41 sec\n",
      "Epoch 62 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7320 | Time: 42.43 sec\n",
      "Epoch 63 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 42.52 sec\n",
      "Epoch 64 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 43.03 sec\n",
      "Epoch 65 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7271 | Time: 42.57 sec\n",
      "Epoch 66 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7239 | Time: 42.85 sec\n",
      "Epoch 67 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7239 | Time: 42.94 sec\n",
      "Epoch 68 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.72 sec\n",
      "Epoch 69 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.39 sec\n",
      "Epoch 70 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.53 sec\n",
      "Epoch 71 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7206 | Time: 44.08 sec\n",
      "Epoch 72 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.40 sec\n",
      "Epoch 73 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 43.84 sec\n",
      "Epoch 74 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 43.88 sec\n",
      "Epoch 75 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.17 sec\n",
      "Epoch 76 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.17 sec\n",
      "Epoch 77 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.28 sec\n",
      "Epoch 78 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.51 sec\n",
      "Epoch 79 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.53 sec\n",
      "Epoch 80 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.75 sec\n",
      "Epoch 81 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.53 sec\n",
      "Epoch 82 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.57 sec\n",
      "Epoch 83 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.46 sec\n",
      "Epoch 84 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.29 sec\n",
      "Epoch 85 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.62 sec\n",
      "Epoch 86 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.73 sec\n",
      "Epoch 87 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.74 sec\n",
      "Epoch 88 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.66 sec\n",
      "Epoch 89 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.80 sec\n",
      "Epoch 90 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.47 sec\n",
      "Epoch 91 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 47.71 sec\n",
      "Epoch 92 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 47.19 sec\n",
      "Epoch 93 | Loss: 413.1744 | Train Acc: 0.9698 | Val Acc: 0.7990 | Time: 44.82 sec\n",
      "Epoch 94 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 45.35 sec\n",
      "Epoch 95 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 45.09 sec\n",
      "Epoch 96 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 47.56 sec\n",
      "Epoch 97 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.86 sec\n",
      "Epoch 98 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.14 sec\n",
      "Epoch 99 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.45 sec\n",
      "Epoch 100 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.77 sec\n"
     ]
    }
   ],
   "source": [
    "# 4. 학습 및 시각화용 리스트\n",
    "import time  # 추가\n",
    "\n",
    "train_acc_list, val_acc_list = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()  # ⏱️ 시작 시간 기록\n",
    "\n",
    "    model.train()\n",
    "    correct, total, loss_total = 0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total += loss.item()\n",
    "        correct += (outputs.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_acc = correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # 검증\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            correct += (outputs.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    val_acc = correct / total\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # ⏱️ 경과 시간 계산\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_total:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Time: {elapsed_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 5. 학습 시각화\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_acc_list\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_acc_list, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_acc_list' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 5. 학습 시각화\n",
    "plt.plot(train_acc_list, label='Train Accuracy')\n",
    "plt.plot(val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. 모델 저장\n",
    "torch.save(model.state_dict(), \"carrot_cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOuDcqCRg6eIRI7JlX9bQBJ",
   "mount_file_id": "1anGnpBZETwMIAh7WflnY9OV7RoBI64V7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
