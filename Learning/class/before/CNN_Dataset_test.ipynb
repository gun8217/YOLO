{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B8znEfIJjQ4L"
   },
   "source": [
    "# SimpleCNN + Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "3eEsshnVjAz3"
   },
   "outputs": [],
   "source": [
    "# ÏÇ¨Ïö©Ïûê Ï†ïÏùò Dataset ÌÅ¥ÎûòÏä§ Ï∂îÍ∞Ä\n",
    "import os\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, label_map, transform=None):\n",
    "        self.samples = []\n",
    "        self.transform = transform\n",
    "        self.label_map = label_map  # Ïòà: {'cat': 0, 'dog': 1}\n",
    "\n",
    "        for class_name, label in label_map.items():\n",
    "            class_path = os.path.join(root_dir, class_name)\n",
    "            for fname in os.listdir(class_path):\n",
    "                if fname.lower().endswith(('.jpg', '.png')):\n",
    "                    self.samples.append((os.path.join(class_path, fname), label))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 381749,
     "status": "ok",
     "timestamp": 1752893537432,
     "user": {
      "displayName": "charlie whisky",
      "userId": "06471801880864215670"
     },
     "user_tz": -540
    },
    "id": "O9rtN25xj4RL",
    "outputId": "a77880d7-3b85-45b1-c0fe-afe3a1daaa15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE= cpu\n",
      "[‚úÖ] GOOD ÌÅ¥ÎûòÏä§ - Ïù¥ÎØ∏ÏßÄ Ïàò: 527\n",
      "[‚úÖ] BAD ÌÅ¥ÎûòÏä§ - Ïù¥ÎØ∏ÏßÄ Ïàò: 550\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# 1. ÌïòÏù¥ÌçºÌååÎùºÎØ∏ÌÑ∞ Î∞è ÏÑ§Ï†ï\n",
    "BATCH_SIZE = 4\n",
    "EPOCHS = 30\n",
    "LR = 0.001\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"DEVICE=\", DEVICE)\n",
    "\n",
    "# 2. Îç∞Ïù¥ÌÑ∞ Ï†ÑÏ≤òÎ¶¨\n",
    "# Ïù¥ÎØ∏ÏßÄÎ•º Ï†ÑÏ≤òÎ¶¨(Preprocessing) ÌïòÍ∏∞ ÏúÑÌïú Ïó∞ÏÜçÎêú Î≥ÄÌôò ÏûëÏóÖ(transform pipeline) ÏùÑ Ï†ïÏùò\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),      # Ïù¥ÎØ∏ÏßÄÎ•º Í≥†Ï†ï ÌÅ¨Í∏∞Î°ú ÏÑ§Ï†ï\n",
    "    transforms.ToTensor(),              # Ïù¥ÎØ∏ÏßÄÎ•º PyTorch ÌÖêÏÑúÎ°ú Î≥ÄÌôò\n",
    "    transforms.Normalize([0.5], [0.5])  # Îπ†Î•¥Í≥† ÏïàÏ†ïÏ†ÅÏù∏ ÌïôÏäµÏùÑ ÏúÑÌïú Ï†ïÍ∑úÌôî(0~1 -> -1~1), (x-0.5)/0.5\n",
    "])\n",
    "data_path = \"C:/Users/602-18/YOLO/Learning/class/before/dataset/carrot\"\n",
    "classes = ['GOOD', 'BAD']\n",
    "image_extensions = ('.jpg', '.jpeg', '.png', '.bmp', '.tiff')\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(data_path, cls)\n",
    "    if not os.path.isdir(class_dir):\n",
    "        print(f\"[‚ùå] ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏùå: {class_dir}\")\n",
    "        continue\n",
    "\n",
    "    images = [f for f in os.listdir(class_dir)\n",
    "              if os.path.isfile(os.path.join(class_dir, f)) and f.lower().endswith(image_extensions)]\n",
    "\n",
    "    print(f\"[‚úÖ] {cls} ÌÅ¥ÎûòÏä§ - Ïù¥ÎØ∏ÏßÄ Ïàò: {len(images)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÌÅ¥ÎûòÏä§ Î™©Î°ù\n",
    "classes = ['GOOD', 'BAD']\n",
    "\n",
    "# Î∂ÑÌï† Ï†ÄÏû• Í≤ΩÎ°ú\n",
    "dest_root = 'C:/Users/602-18/YOLO/Learning/class/before/dataset_split/carrot'\n",
    "\n",
    "# # 4. Î∂ÑÌï† ÎπÑÏú®\n",
    "# split_ratio = [0.8, 0.19, 0.01]\n",
    "# splits = ['train', 'val', 'test']\n",
    "\n",
    "# # 5. ÎåÄÏÉÅ Ìè¥Îçî Íµ¨Ï°∞ ÏÉùÏÑ±: .../carrot/train/GOOD Îì±\n",
    "# for split in splits:\n",
    "#     for cls in classes:\n",
    "#         split_cls_dir = os.path.join(dest_root, split, cls)\n",
    "#         os.makedirs(split_cls_dir, exist_ok=True)\n",
    "\n",
    "# # 6. Ïù¥ÎØ∏ÏßÄ Î∂ÑÌï† Î∞è Î≥µÏÇ¨\n",
    "# for cls in classes:\n",
    "#     src_dir = os.path.join(data_path, cls)\n",
    "#     if not os.path.isdir(src_dir):\n",
    "#         print(f\"[‚ùå] ÎîîÎ†âÌÜ†Î¶¨ ÏóÜÏùå: {src_dir}\")\n",
    "#         continue\n",
    "\n",
    "#     images = [f for f in os.listdir(src_dir) if os.path.isfile(os.path.join(src_dir, f))]\n",
    "#     random.shuffle(images)\n",
    "\n",
    "#     total = len(images)\n",
    "#     train_end = int(split_ratio[0] * total)\n",
    "#     val_end = train_end + int(split_ratio[1] * total)\n",
    "\n",
    "#     split_files = {\n",
    "#         'train': images[:train_end],\n",
    "#         'val': images[train_end:val_end],\n",
    "#         'test': images[val_end:]\n",
    "#     }\n",
    "\n",
    "#     for split, file_list in split_files.items():\n",
    "#         for img in file_list:\n",
    "#             src = os.path.join(src_dir, img)\n",
    "#             dst = os.path.join(dest_root, split, cls, img)\n",
    "#             os.makedirs(os.path.dirname(dst), exist_ok=True)\n",
    "#             shutil.copy(src, dst)\n",
    "\n",
    "# print(\"‚úÖ Ïù¥ÎØ∏ÏßÄ Î∂ÑÌï† Î∞è Î≥µÏÇ¨Í∞Ä ÏôÑÎ£åÎêòÏóàÏäµÎãàÎã§.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[üìÅ] ÌÅ¥ÎûòÏä§: GOOD | Ïù¥ÎØ∏ÏßÄ Ïàò: 100\n",
      "[üìÅ] ÌÅ¥ÎûòÏä§: BAD | Ïù¥ÎØ∏ÏßÄ Ïàò: 104\n",
      "‚úÖ val Ïù¥ÎØ∏ÏßÄÏóê ÎåÄÌïú Ï¶ùÍ∞ï ÏôÑÎ£å Î∞è Ï†ÄÏû•Îê®.\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms.functional as F\n",
    "val_dir = 'C:/Users/602-18/YOLO/Learning/class/before/dataset_split/carrot/val'\n",
    "\n",
    "num_aug_per_image = 2\n",
    "def augment_image(image):\n",
    "    if random.random() > 0.5:\n",
    "        image = F.hflip(image)                           # Î∞òÏ†Ñ\n",
    "    if random.random() > 0.5:\n",
    "        angle = random.uniform(-30, 30)\n",
    "        image = F.rotate(image, angle)                   # ÌöåÏ†Ñ\n",
    "    if random.random() > 0.5:\n",
    "        brightness = random.uniform(0.7, 1.3)\n",
    "        contrast = random.uniform(0.7, 1.3)\n",
    "        image = F.adjust_brightness(image, brightness)   # Î∞ùÍ∏∞ Ï°∞Ï†à\n",
    "        image = F.adjust_contrast(image, contrast)       # Î™ÖÏïî Ï°∞Ï†à\n",
    "    return image\n",
    "\n",
    "# Ïù¥ÎØ∏ÏßÄ ÌôïÏû•Ïûê\n",
    "image_exts = ('.jpg', '.jpeg', '.png')\n",
    "\n",
    "for cls in classes:\n",
    "    class_dir = os.path.join(val_dir, cls)\n",
    "    images = [f for f in os.listdir(class_dir) if f.lower().endswith(image_exts)]\n",
    "\n",
    "    print(f\"[üìÅ] ÌÅ¥ÎûòÏä§: {cls} | Ïù¥ÎØ∏ÏßÄ Ïàò: {len(images)}\")\n",
    "\n",
    "    for img_name in images:\n",
    "        img_path = os.path.join(class_dir, img_name)\n",
    "\n",
    "        try:\n",
    "            image = Image.open(img_path).convert(\"RGB\")\n",
    "        except Exception as e:\n",
    "            print(f\"[‚ö†Ô∏è] Ïù¥ÎØ∏ÏßÄ Ïó¥Í∏∞ Ïã§Ìå®: {img_path}, ÏóêÎü¨: {e}\")\n",
    "            continue\n",
    "\n",
    "        for i in range(num_aug_per_image):\n",
    "            aug_img = augment_image(image)\n",
    "            base, ext = os.path.splitext(img_name)\n",
    "            new_filename = f\"aug_{base}_{i}{ext}\"\n",
    "            new_path = os.path.join(class_dir, new_filename)\n",
    "            aug_img.save(new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(img, stddev=50):\n",
    "    arr = np.array(img).astype(np.float32)\n",
    "    noise = np.random.normal(0, stddev, arr.shape)\n",
    "    noisy_arr = np.clip(arr + noise, 0, 255).astype(np.uint8)\n",
    "    return Image.fromarray(noisy_arr)\n",
    "\n",
    "def apply_affine(img):\n",
    "    width, height = img.size\n",
    "    coeffs = (1, 0.2, -10,   # a, b, c\n",
    "              0.1, 1, -5)    # d, e, f\n",
    "    return img.transform((width, height), Image.AFFINE, coeffs, resample=Image.BICUBIC)\n",
    "\n",
    "def apply_rotation(img, angle=4):\n",
    "    return img.rotate(angle, resample=Image.BICUBIC, expand=True).crop((0, 0, img.size[0], img.size[1]))\n",
    "\n",
    "def apply_random_crop_resize(img, crop_ratio=0.9):\n",
    "    w, h = img.size\n",
    "    crop_w, crop_h = int(w * crop_ratio), int(h * crop_ratio)\n",
    "    left = np.random.randint(0, w - crop_w + 1)\n",
    "    top = np.random.randint(0, h - crop_h + 1)\n",
    "    cropped = img.crop((left, top, left + crop_w, top + crop_h))\n",
    "    return cropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_map Ï†ïÏùò\n",
    "label_map = {'BAD': 0, 'GOOD': 1}\n",
    "class_names = list(label_map.keys())\n",
    "\n",
    "# Ïª§Ïä§ÌÖÄ Dataset Ï†ÅÏö©\n",
    "train_dataset = CustomImageDataset(root_dir=dest_root+'/train', label_map=label_map, transform=transform)\n",
    "valid_dataset = CustomImageDataset(root_dir=dest_root+'/val', label_map=label_map, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)  # Î™®Îç∏Ïù¥ ÏàúÏÑúÏóê ÏòÅÌñ•ÏùÑ Î∞õÏßÄ ÏïäÎèÑÎ°ù Îß§ epochÎßàÎã§ Î¨¥ÏûëÏúÑÎ°ú ÏÑûÎäîÎã§\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=BATCH_SIZE, shuffle=False) # Îç∞Ïù¥ÌÑ∞ ÏàúÏÑú Í≥†Ï†ï\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "EhAo7ZPSkY3y"
   },
   "outputs": [],
   "source": [
    "# 3. Î™®Îç∏ Ï†ïÏùò\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Sequential(\n",
    "            # nn.Conv2d(3Ï±ÑÎÑê(RGB), ÌïÑÌÑ∞Ïàò, ÌïÑÌÑ∞ÌÅ¨Í∏∞, stride=1, padding=0)\n",
    "            nn.Conv2d(3, 16, 3, padding=1),  # 128x128x3 -> 128x128x16, padding=1ÏùÄ 1ÌîΩÏÖÄ Ï∂îÍ∞ÄÌïòÏó¨ Ï∂úÎ†•ÌÅ¨Í∏∞ Ïú†ÏßÄ\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # -> 64x64x16, Ïù¥ÎØ∏ÏßÄ ÌÅ¨Í∏∞Î•º 1/2Î°ú Ï∂ïÏÜå(Íµ≠ÏÜåÏ†Å ÌäπÏßï ÏöîÏïΩ)\n",
    "            nn.Conv2d(16, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),                # -> 32x32x32\n",
    "        )\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(32 * 32 * 32, 224),  # ÏûÖÎ†•ÏùÄ CNNÏóêÏÑú Ï†ÑÎã¨Îêú ÌÅ¨Í∏∞, Ï∂úÎ†•ÏùÄ Î≥¥ÌÜµ 64, 128, 256, 512 Îì±\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(224, 2)   # ÏµúÏ¢Ö Ï∂úÎ†•Ïù¥ 1Ïù¥Î©¥ SigmoidÏó∞Í≤∞, 2Ïù¥Î©¥ SoftmaxÏó∞Í≤∞\n",
    "            # BCEWithLogitsLoss() (ÎòêÎäî BCELoss + Sigmoid),\tCrossEntropyLoss() (Softmax Ìè¨Ìï®)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(self.conv(x))\n",
    "\n",
    "model = SimpleCNN().to(DEVICE)\n",
    "criterion = nn.CrossEntropyLoss()  # Softmax Ìè¨Ìï®\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Loss: 10.8846 | Train Acc: 0.9837 | Val Acc: 0.8284 | Time: 41.50 sec\n",
      "Epoch 2 | Loss: 0.0040 | Train Acc: 1.0000 | Val Acc: 0.8301 | Time: 41.53 sec\n",
      "Epoch 3 | Loss: 0.0008 | Train Acc: 1.0000 | Val Acc: 0.8268 | Time: 42.23 sec\n",
      "Epoch 4 | Loss: 0.0004 | Train Acc: 1.0000 | Val Acc: 0.8235 | Time: 43.20 sec\n",
      "Epoch 5 | Loss: 0.0002 | Train Acc: 1.0000 | Val Acc: 0.8235 | Time: 42.62 sec\n",
      "Epoch 6 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8219 | Time: 42.57 sec\n",
      "Epoch 7 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8186 | Time: 42.98 sec\n",
      "Epoch 8 | Loss: 0.0001 | Train Acc: 1.0000 | Val Acc: 0.8154 | Time: 42.69 sec\n",
      "Epoch 9 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8121 | Time: 42.43 sec\n",
      "Epoch 10 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8088 | Time: 43.85 sec\n",
      "Epoch 11 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8072 | Time: 43.45 sec\n",
      "Epoch 12 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8072 | Time: 43.43 sec\n",
      "Epoch 13 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8039 | Time: 42.80 sec\n",
      "Epoch 14 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8056 | Time: 42.73 sec\n",
      "Epoch 15 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 42.78 sec\n",
      "Epoch 16 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 43.22 sec\n",
      "Epoch 17 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8023 | Time: 43.19 sec\n",
      "Epoch 18 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.8007 | Time: 42.91 sec\n",
      "Epoch 19 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 42.40 sec\n",
      "Epoch 20 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7974 | Time: 44.43 sec\n",
      "Epoch 21 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7941 | Time: 43.61 sec\n",
      "Epoch 22 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.07 sec\n",
      "Epoch 23 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.38 sec\n",
      "Epoch 24 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7908 | Time: 43.35 sec\n",
      "Epoch 25 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7876 | Time: 43.30 sec\n",
      "Epoch 26 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7859 | Time: 42.57 sec\n",
      "Epoch 27 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7810 | Time: 43.00 sec\n",
      "Epoch 28 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7827 | Time: 42.05 sec\n",
      "Epoch 29 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7810 | Time: 42.33 sec\n",
      "Epoch 30 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7778 | Time: 42.10 sec\n",
      "Epoch 31 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7778 | Time: 42.86 sec\n",
      "Epoch 32 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7745 | Time: 42.70 sec\n",
      "Epoch 33 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7729 | Time: 42.66 sec\n",
      "Epoch 34 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7647 | Time: 42.97 sec\n",
      "Epoch 35 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7614 | Time: 42.32 sec\n",
      "Epoch 36 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7582 | Time: 42.45 sec\n",
      "Epoch 37 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7565 | Time: 42.48 sec\n",
      "Epoch 38 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7549 | Time: 43.20 sec\n",
      "Epoch 39 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7549 | Time: 44.07 sec\n",
      "Epoch 40 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7516 | Time: 42.17 sec\n",
      "Epoch 41 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7516 | Time: 42.53 sec\n",
      "Epoch 42 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7500 | Time: 45.50 sec\n",
      "Epoch 43 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7484 | Time: 43.58 sec\n",
      "Epoch 44 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 42.47 sec\n",
      "Epoch 45 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 42.18 sec\n",
      "Epoch 46 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7451 | Time: 43.18 sec\n",
      "Epoch 47 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7418 | Time: 43.35 sec\n",
      "Epoch 48 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7418 | Time: 42.25 sec\n",
      "Epoch 49 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.18 sec\n",
      "Epoch 50 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.16 sec\n",
      "Epoch 51 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.82 sec\n",
      "Epoch 52 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.15 sec\n",
      "Epoch 53 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7386 | Time: 42.90 sec\n",
      "Epoch 54 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.70 sec\n",
      "Epoch 55 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.60 sec\n",
      "Epoch 56 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7369 | Time: 42.18 sec\n",
      "Epoch 57 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.15 sec\n",
      "Epoch 58 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7337 | Time: 42.50 sec\n",
      "Epoch 59 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.65 sec\n",
      "Epoch 60 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7353 | Time: 42.63 sec\n",
      "Epoch 61 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 42.41 sec\n",
      "Epoch 62 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7320 | Time: 42.43 sec\n",
      "Epoch 63 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 42.52 sec\n",
      "Epoch 64 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7304 | Time: 43.03 sec\n",
      "Epoch 65 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7271 | Time: 42.57 sec\n",
      "Epoch 66 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7239 | Time: 42.85 sec\n",
      "Epoch 67 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7239 | Time: 42.94 sec\n",
      "Epoch 68 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.72 sec\n",
      "Epoch 69 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.39 sec\n",
      "Epoch 70 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7222 | Time: 43.53 sec\n",
      "Epoch 71 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7206 | Time: 44.08 sec\n",
      "Epoch 72 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.40 sec\n",
      "Epoch 73 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 43.84 sec\n",
      "Epoch 74 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 43.88 sec\n",
      "Epoch 75 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.17 sec\n",
      "Epoch 76 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.17 sec\n",
      "Epoch 77 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.28 sec\n",
      "Epoch 78 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.51 sec\n",
      "Epoch 79 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.53 sec\n",
      "Epoch 80 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.75 sec\n",
      "Epoch 81 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 44.53 sec\n",
      "Epoch 82 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.57 sec\n",
      "Epoch 83 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.46 sec\n",
      "Epoch 84 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.29 sec\n",
      "Epoch 85 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.62 sec\n",
      "Epoch 86 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.73 sec\n",
      "Epoch 87 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.74 sec\n",
      "Epoch 88 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.66 sec\n",
      "Epoch 89 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 44.80 sec\n",
      "Epoch 90 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7190 | Time: 45.47 sec\n",
      "Epoch 91 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 47.71 sec\n",
      "Epoch 92 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7173 | Time: 47.19 sec\n",
      "Epoch 93 | Loss: 413.1744 | Train Acc: 0.9698 | Val Acc: 0.7990 | Time: 44.82 sec\n",
      "Epoch 94 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 45.35 sec\n",
      "Epoch 95 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 45.09 sec\n",
      "Epoch 96 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 47.56 sec\n",
      "Epoch 97 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.86 sec\n",
      "Epoch 98 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.14 sec\n",
      "Epoch 99 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.45 sec\n",
      "Epoch 100 | Loss: 0.0000 | Train Acc: 1.0000 | Val Acc: 0.7990 | Time: 46.77 sec\n"
     ]
    }
   ],
   "source": [
    "# 4. ÌïôÏäµ Î∞è ÏãúÍ∞ÅÌôîÏö© Î¶¨Ïä§Ìä∏\n",
    "import time  # Ï∂îÍ∞Ä\n",
    "\n",
    "train_acc_list, val_acc_list = [], []\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    start_time = time.time()  # ‚è±Ô∏è ÏãúÏûë ÏãúÍ∞Ñ Í∏∞Î°ù\n",
    "\n",
    "    model.train()\n",
    "    correct, total, loss_total = 0, 0, 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_total += loss.item()\n",
    "        correct += (outputs.argmax(1) == y).sum().item()\n",
    "        total += y.size(0)\n",
    "    train_acc = correct / total\n",
    "    train_acc_list.append(train_acc)\n",
    "\n",
    "    # Í≤ÄÏ¶ù\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in valid_loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            outputs = model(x)\n",
    "            correct += (outputs.argmax(1) == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    val_acc = correct / total\n",
    "    val_acc_list.append(val_acc)\n",
    "\n",
    "    elapsed_time = time.time() - start_time  # ‚è±Ô∏è Í≤ΩÍ≥º ÏãúÍ∞Ñ Í≥ÑÏÇ∞\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Loss: {loss_total:.4f} | Train Acc: {train_acc:.4f} | Val Acc: {val_acc:.4f} | Time: {elapsed_time:.2f} sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_acc_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# 5. ÌïôÏäµ ÏãúÍ∞ÅÌôî\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(\u001b[43mtrain_acc_list\u001b[49m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTrain Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(val_acc_list, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation Accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m plt\u001b[38;5;241m.\u001b[39mxlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_acc_list' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 5. ÌïôÏäµ ÏãúÍ∞ÅÌôî\n",
    "plt.plot(train_acc_list, label='Train Accuracy')\n",
    "plt.plot(val_acc_list, label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Training Progress')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# 6. Î™®Îç∏ Ï†ÄÏû•\n",
    "torch.save(model.state_dict(), \"carrot_cnn.pth\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOuDcqCRg6eIRI7JlX9bQBJ",
   "mount_file_id": "1anGnpBZETwMIAh7WflnY9OV7RoBI64V7",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "yolov8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
