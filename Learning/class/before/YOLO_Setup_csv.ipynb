{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","mount_file_id":"1OJQb3cU-ZOe1KWwRLptMNDHnyafUKdPn","authorship_tag":"ABX9TyMqz3zi9Wn5UIIHHwXJpGs2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# YOLO Setup & Retrieve, CSV\n","* https://docs.ultralytics.com/ko/tasks/pose/\n","* https://docs.ultralytics.com/ko/datasets/pose/coco/\n","* 실행환경 : Google Colab"],"metadata":{"id":"SjbdtEPqDkzU"}},{"cell_type":"markdown","source":["## YOLO11 설치"],"metadata":{"id":"qUZcsa8-Ea3T"}},{"cell_type":"code","execution_count":1,"metadata":{"id":"PiRhggnGDSpB","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753170112279,"user_tz":-540,"elapsed":85891,"user":{"displayName":"charlie whisky","userId":"06471801880864215670"}},"outputId":"b2c51f0a-b278-4eea-acf5-5e812ebc99ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.168-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (11.2.1)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.32.3)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (1.15.3)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (2.6.0+cu124)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (0.21.0+cu124)\n","Requirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.11/dist-packages (from ultralytics) (4.67.1)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.11/dist-packages (from ultralytics) (9.0.0)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.14-py3-none-any.whl.metadata (9.4 kB)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.59.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.8)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2.4.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.23.0->ultralytics) (2025.7.14)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (4.14.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n","Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (12.4.127)\n","Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=1.8.0->ultralytics)\n","  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.168-py3-none-any.whl (1.0 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m42.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m37.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.14-py3-none-any.whl (26 kB)\n","Installing collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ultralytics-thop, ultralytics\n","  Attempting uninstall: nvidia-nvjitlink-cu12\n","    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n","    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n","      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n","  Attempting uninstall: nvidia-curand-cu12\n","    Found existing installation: nvidia-curand-cu12 10.3.6.82\n","    Uninstalling nvidia-curand-cu12-10.3.6.82:\n","      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n","  Attempting uninstall: nvidia-cufft-cu12\n","    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n","    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n","      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n","  Attempting uninstall: nvidia-cuda-runtime-cu12\n","    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n","    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n","    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n","    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n","  Attempting uninstall: nvidia-cuda-cupti-cu12\n","    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n","    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n","      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n","  Attempting uninstall: nvidia-cublas-cu12\n","    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n","    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n","      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n","  Attempting uninstall: nvidia-cusparse-cu12\n","    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n","    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n","      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n","  Attempting uninstall: nvidia-cudnn-cu12\n","    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n","    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n","      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n","  Attempting uninstall: nvidia-cusolver-cu12\n","    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n","    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n","      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n","Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 ultralytics-8.3.168 ultralytics-thop-2.0.14\n"]}],"source":["!pip install ultralytics opencv-python pandas\n"]},{"cell_type":"markdown","source":["## MP4 비디오에서 관절 좌표(x, y) 추출, CSV에 저장, visibility는 제외함\n","* mp4 비디오 다운로드 사이트 : https://www.istockphoto.com/"],"metadata":{"id":"81eHW4lYEdhL"}},{"cell_type":"code","source":["import cv2\n","import pandas as pd\n","from ultralytics import YOLO\n","\n","# 1. 모델 불러오기 (Pose Estimation용)\n","model = YOLO('yolo11n-pose.pt')  # 또는 yolov8s-pose.pt, yolov8m-pose.pt\n","\n","# 2. 비디오 불러오기\n","video_path = '/content/drive/MyDrive/Python_AI/YOLO/test_mp4/walk_sample_video.mp4'  # 비디오 파일 경로\n","cap = cv2.VideoCapture(video_path)\n","\n","frame_idx = 0\n","data = []\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # 3. 포즈 추론\n","    results = model(frame)\n","\n","    # 4. 결과에서 keypoints 추출\n","    for result in results:\n","        keypoints = result.keypoints\n","        if keypoints is not None:\n","            for person in keypoints.xy:  # [n_persons, 17, 2] - x, y\n","                row = {'frame': frame_idx}\n","                for i, (x, y) in enumerate(person):\n","                    row[f'x{i}'] = float(x)\n","                    row[f'y{i}'] = float(y)\n","                data.append(row)\n","\n","    frame_idx += 1\n","\n","cap.release()\n","\n","# 5. CSV로 저장\n","df = pd.DataFrame(data)\n","df.to_csv('/content/drive/MyDrive/Python_AI/YOLO/train_data/walk_sample_video.csv', index=False)\n","\n","print(\"✅ CSV 저장 완료: pose_keypoints.csv\")\n"],"metadata":{"id":"AT-LcYiIDnaE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1753170417055,"user_tz":-540,"elapsed":8778,"user":{"displayName":"charlie whisky","userId":"06471801880864215670"}},"outputId":"4580dc5b-24d6-486e-93dc-c8f028413a3c"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.97M/5.97M [00:00<00:00, 342MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["✅ CSV 저장 완료: pose_keypoints.csv\n"]}]},{"cell_type":"markdown","source":["## 영상 위에 keypoints를 표시하여 다른 mp4 파일에 저장하는 예"],"metadata":{"id":"DgmHKrLyZfCd"}},{"cell_type":"code","source":["import cv2\n","from ultralytics import YOLO\n","\n","# 모델 경로 (사용자가 직접 훈련한 경우 해당 경로 사용)\n","model = YOLO('yolo11n-pose.pt')\n","\n","# 입력 비디오 경로\n","input_video_path = '/content/drive/MyDrive/Python_AI/YOLO/run_70frames_video.mp4'\n","cap = cv2.VideoCapture(input_video_path)\n","\n","# 출력 비디오 설정\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","out = cv2.VideoWriter('output_pose.mp4', fourcc, fps, (width, height))\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO Pose 추론\n","    results = model(frame)\n","\n","    # 키포인트 시각화 및 출력 프레임 저장\n","    for result in results:\n","        if result.keypoints is not None:\n","            for person in result.keypoints.xy:\n","                for (x, y) in person:\n","                    # 각 키포인트에 점 찍기\n","                    cv2.circle(frame, (int(x), int(y)), radius=1, color=(0, 255, 0), thickness=-1)\n","\n","    # 프레임 저장\n","    out.write(frame)\n","\n","cap.release()\n","out.release()\n","\n","print(\"✅ 완료: output_pose.mp4 저장됨.\")\n"],"metadata":{"id":"pJ19ssl1QDs9","colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"status":"ok","timestamp":1753170442024,"user_tz":-540,"elapsed":15129,"user":{"displayName":"charlie whisky","userId":"06471801880864215670"}},"outputId":"8ea9034d-7b05-405a-c3b4-2a3af1e4d590"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","0: 480x640 1 person, 407.4ms\n","Speed: 12.4ms preprocess, 407.4ms inference, 37.7ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 101.0ms\n","Speed: 43.8ms preprocess, 101.0ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.2ms\n","Speed: 1.9ms preprocess, 86.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.9ms\n","Speed: 1.9ms preprocess, 88.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 79.9ms\n","Speed: 1.9ms preprocess, 79.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 91.9ms\n","Speed: 1.9ms preprocess, 91.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.4ms\n","Speed: 1.7ms preprocess, 84.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 89.0ms\n","Speed: 1.6ms preprocess, 89.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.0ms\n","Speed: 1.5ms preprocess, 86.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 87.8ms\n","Speed: 1.6ms preprocess, 87.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.8ms\n","Speed: 1.6ms preprocess, 86.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.4ms\n","Speed: 1.6ms preprocess, 84.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.6ms\n","Speed: 1.7ms preprocess, 81.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.4ms\n","Speed: 2.1ms preprocess, 84.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 80.3ms\n","Speed: 1.6ms preprocess, 80.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 92.9ms\n","Speed: 1.8ms preprocess, 92.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.6ms\n","Speed: 1.8ms preprocess, 81.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.0ms\n","Speed: 1.6ms preprocess, 88.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.5ms\n","Speed: 1.7ms preprocess, 84.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 87.2ms\n","Speed: 1.6ms preprocess, 87.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.5ms\n","Speed: 1.7ms preprocess, 86.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.6ms\n","Speed: 2.2ms preprocess, 88.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 85.9ms\n","Speed: 3.0ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 91.9ms\n","Speed: 1.6ms preprocess, 91.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 89.5ms\n","Speed: 1.9ms preprocess, 89.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.5ms\n","Speed: 1.6ms preprocess, 86.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.3ms\n","Speed: 1.7ms preprocess, 84.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.6ms\n","Speed: 1.7ms preprocess, 86.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.8ms\n","Speed: 1.6ms preprocess, 84.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 82.3ms\n","Speed: 1.6ms preprocess, 82.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.1ms\n","Speed: 2.6ms preprocess, 88.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.9ms\n","Speed: 1.6ms preprocess, 86.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.9ms\n","Speed: 1.6ms preprocess, 84.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.3ms\n","Speed: 1.7ms preprocess, 84.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.9ms\n","Speed: 1.6ms preprocess, 81.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 82.8ms\n","Speed: 1.7ms preprocess, 82.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.6ms\n","Speed: 1.6ms preprocess, 84.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 92.2ms\n","Speed: 1.7ms preprocess, 92.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 85.9ms\n","Speed: 1.7ms preprocess, 85.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 82.3ms\n","Speed: 2.0ms preprocess, 82.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.0ms\n","Speed: 1.7ms preprocess, 84.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.1ms\n","Speed: 1.5ms preprocess, 84.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 96.8ms\n","Speed: 1.8ms preprocess, 96.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 94.1ms\n","Speed: 1.6ms preprocess, 94.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.6ms\n","Speed: 1.9ms preprocess, 88.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 87.0ms\n","Speed: 1.7ms preprocess, 87.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 87.2ms\n","Speed: 1.6ms preprocess, 87.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 92.8ms\n","Speed: 2.4ms preprocess, 92.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 93.2ms\n","Speed: 1.7ms preprocess, 93.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 84.6ms\n","Speed: 1.7ms preprocess, 84.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 85.8ms\n","Speed: 1.7ms preprocess, 85.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 87.4ms\n","Speed: 1.8ms preprocess, 87.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 90.2ms\n","Speed: 1.7ms preprocess, 90.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 94.4ms\n","Speed: 2.8ms preprocess, 94.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 83.7ms\n","Speed: 2.6ms preprocess, 83.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 79.3ms\n","Speed: 2.1ms preprocess, 79.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 77.3ms\n","Speed: 1.9ms preprocess, 77.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 79.7ms\n","Speed: 2.3ms preprocess, 79.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 79.7ms\n","Speed: 1.9ms preprocess, 79.7ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 82.0ms\n","Speed: 2.0ms preprocess, 82.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.0ms\n","Speed: 2.3ms preprocess, 81.0ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.8ms\n","Speed: 1.9ms preprocess, 81.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 81.1ms\n","Speed: 2.0ms preprocess, 81.1ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 83.4ms\n","Speed: 2.0ms preprocess, 83.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 91.1ms\n","Speed: 1.6ms preprocess, 91.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 82.1ms\n","Speed: 1.6ms preprocess, 82.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.3ms\n","Speed: 1.6ms preprocess, 88.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 88.1ms\n","Speed: 1.7ms preprocess, 88.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 86.0ms\n","Speed: 1.7ms preprocess, 86.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","\n","0: 480x640 1 person, 85.7ms\n","Speed: 1.6ms preprocess, 85.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n","✅ 완료: output_pose.mp4 저장됨.\n"]}]},{"cell_type":"code","source":["# 관절 사이에 선 그리기\n","import cv2\n","from ultralytics import YOLO\n","\n","# 모델 로드\n","model = YOLO('yolo11n-pose.pt')\n","\n","# 비디오 열기\n","input_video_path = '/content/drive/MyDrive/Python_AI/YOLO/run_70frames_video.mp4'\n","cap = cv2.VideoCapture(input_video_path)\n","\n","# 출력 비디오 설정\n","fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n","fps = cap.get(cv2.CAP_PROP_FPS)\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","out = cv2.VideoWriter('output_pose.mp4', fourcc, fps, (width, height))\n","\n","# COCO 17 keypoints 연결 구조 (skeleton)\n","# (참고: COCO keypoints index 정의에 따른 연결)\n","skeleton = [\n","    (5, 7), (7, 9),     # left arm\n","    (6, 8), (8, 10),    # right arm\n","    (5, 6),             # shoulders\n","    (11, 13), (13, 15), # left leg\n","    (12, 14), (14, 16), # right leg\n","    (11, 12),           # hips\n","    (5, 11), (6, 12),   # torso sides\n","    (0, 1), (1, 3), (0, 2), (2, 4), # eyes to ears\n","    (0, 5), (0, 6)      # head to shoulders\n","]\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # YOLO Pose 추론\n","    results = model(frame)\n","\n","    for result in results:\n","        if result.keypoints is not None:\n","            for person in result.keypoints.xy:\n","                keypoints = person.cpu().numpy()\n","\n","                # 점 찍기\n","                for x, y in keypoints:\n","                    cv2.circle(frame, (int(x), int(y)), radius=2, color=(0, 255, 0), thickness=-1)\n","\n","                # 선 그리기 (관절 연결)\n","                for idx1, idx2 in skeleton:\n","                    if idx1 < len(keypoints) and idx2 < len(keypoints):\n","                        x1, y1 = keypoints[idx1]\n","                        x2, y2 = keypoints[idx2]\n","                        if x1 > 0 and y1 > 0 and x2 > 0 and y2 > 0:  # 존재하는 키포인트만 연결\n","                            cv2.line(frame, (int(x1), int(y1)), (int(x2), int(y2)), color=(255, 0, 0), thickness=1)\n","\n","    out.write(frame)\n","\n","cap.release()\n","out.release()\n","\n","print(\"✅ 완료: output_pose.mp4 저장됨.\")\n"],"metadata":{"id":"ho6t6NtuEtPc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## MP4에서 [x, y, visible] 값을 추출하여  CSV 파일에 저장하기\n","* YOLOv11 또는 YOLOv8의 *-pose.pt 모델(예: yolo11n-pose.pt, yolov8n-pose.pt)은 Ultralytics의 COCO Pose 포맷(17 keypoints)을 따름\n","* x : 이미지 픽셀 x 좌표(이미지 왼쪽 0)\n","* y : 이미지 픽셀 y 좌표(이미지 상단 0)\n","* visible : confidence, visibility(0~1 사잇값) 0(보이지 않음), 0.5(불확실함), 1(보임)\n","* visible값은 ML모델 학습시에 손실 계산에서 가중치로 사용할 수 있다(아래 참조)\n","* loss = torch.mean(visible * (y_pred - y_true) ** 2)"],"metadata":{"id":"E-F2Ub2ViUKm"}},{"cell_type":"code","source":["!pip install ultralytics opencv-python pandas"],"metadata":{"id":"65z2k7H8PzWi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import pandas as pd\n","from ultralytics import YOLO\n","\n","# 1. 모델 로드\n","model = YOLO('yolo11n-pose.pt')  # 또는 yolov8n-pose.pt\n","\n","# 2. 비디오 로드\n","video_path = '/content/drive/MyDrive/Python_AI/YOLO/walk_man_right_with_phone.mp4'\n","cap = cv2.VideoCapture(video_path)\n","\n","# 폭 (width), 높이 (height) 구하기\n","width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n","height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n","\n","frame_idx = 0\n","data = []\n","\n","while cap.isOpened():\n","    ret, frame = cap.read()\n","    if not ret:\n","        break\n","\n","    # 3. 포즈 추론\n","    results = model(frame)\n","\n","    # 4. 결과에서 키포인트 [x, y, visible] 추출\n","    for result in results:\n","        keypoints = result.keypoints  # result.keypoints.xy: [x, y], result.keypoints.conf: visible\n","        if keypoints is not None:\n","            for person_idx, (coords_xy, visibility) in enumerate(zip(keypoints.xy, keypoints.conf)):\n","                #row = {'frame': frame_idx, 'person': person_idx}   # 다수의 사람을 대상으로 하는 경우\n","                row = {'frame': frame_idx}     # 첫번째 사람만 대상으로 하는 경우\n","                for i, ((x, y), v) in enumerate(zip(coords_xy, visibility)):\n","                    row[f'x{i}'] = float(x)\n","                    row[f'y{i}'] = float(y)\n","                    row[f'v{i}'] = float(v)  # visible/confidence 값\n","                data.append(row)\n","\n","    frame_idx += 1\n","\n","cap.release()\n","\n","# 5. CSV 저장\n","df = pd.DataFrame(data)\n","df.to_csv('/content/drive/MyDrive/Python_AI/YOLO/train_data/walk_man_right_with_phone.csv', index=False)\n","\n","print(\"✅ 완료: csv 저장됨\")\n"],"metadata":{"id":"yAe2wM3EZmql","collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1750225007349,"user_tz":-540,"elapsed":62576,"user":{"displayName":"charlie whisky","userId":"06471801880864215670"}},"outputId":"4ce2a6d9-711a-4ef7-a9c8-4ea779f5ed35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n","Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n-pose.pt to 'yolo11n-pose.pt'...\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 5.97M/5.97M [00:00<00:00, 114MB/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","0: 384x640 1 person, 340.6ms\n","Speed: 18.4ms preprocess, 340.6ms inference, 32.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 135.6ms\n","Speed: 4.7ms preprocess, 135.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.0ms\n","Speed: 4.5ms preprocess, 146.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 153.7ms\n","Speed: 5.0ms preprocess, 153.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.8ms\n","Speed: 4.8ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.4ms\n","Speed: 3.7ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.0ms\n","Speed: 4.4ms preprocess, 139.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.3ms\n","Speed: 5.1ms preprocess, 138.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.8ms\n","Speed: 3.1ms preprocess, 144.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 153.2ms\n","Speed: 3.8ms preprocess, 153.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.8ms\n","Speed: 4.6ms preprocess, 142.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.7ms\n","Speed: 3.6ms preprocess, 143.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.4ms\n","Speed: 14.8ms preprocess, 144.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.1ms\n","Speed: 5.1ms preprocess, 145.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.9ms\n","Speed: 4.6ms preprocess, 139.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.9ms\n","Speed: 4.8ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 151.4ms\n","Speed: 5.7ms preprocess, 151.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.3ms\n","Speed: 4.9ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.9ms\n","Speed: 4.9ms preprocess, 144.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.7ms\n","Speed: 5.2ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.4ms\n","Speed: 4.6ms preprocess, 141.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 166.5ms\n","Speed: 5.2ms preprocess, 166.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 158.8ms\n","Speed: 4.4ms preprocess, 158.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.8ms\n","Speed: 5.0ms preprocess, 144.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.2ms\n","Speed: 5.7ms preprocess, 145.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.4ms\n","Speed: 5.1ms preprocess, 143.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 134.1ms\n","Speed: 5.9ms preprocess, 134.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.0ms\n","Speed: 5.2ms preprocess, 145.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.1ms\n","Speed: 4.6ms preprocess, 143.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 159.3ms\n","Speed: 5.6ms preprocess, 159.3ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 229.9ms\n","Speed: 5.1ms preprocess, 229.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 220.2ms\n","Speed: 5.5ms preprocess, 220.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.2ms\n","Speed: 5.5ms preprocess, 212.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 217.6ms\n","Speed: 3.7ms preprocess, 217.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.2ms\n","Speed: 5.0ms preprocess, 212.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 204.4ms\n","Speed: 4.7ms preprocess, 204.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 217.2ms\n","Speed: 5.0ms preprocess, 217.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 214.8ms\n","Speed: 7.0ms preprocess, 214.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 224.4ms\n","Speed: 5.6ms preprocess, 224.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 209.4ms\n","Speed: 7.4ms preprocess, 209.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 224.2ms\n","Speed: 5.2ms preprocess, 224.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 207.5ms\n","Speed: 5.5ms preprocess, 207.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 222.4ms\n","Speed: 6.3ms preprocess, 222.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 241.3ms\n","Speed: 5.9ms preprocess, 241.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 223.5ms\n","Speed: 5.3ms preprocess, 223.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 219.7ms\n","Speed: 5.2ms preprocess, 219.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 221.4ms\n","Speed: 4.9ms preprocess, 221.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 156.1ms\n","Speed: 4.9ms preprocess, 156.1ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.0ms\n","Speed: 5.3ms preprocess, 143.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.9ms\n","Speed: 4.5ms preprocess, 139.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.9ms\n","Speed: 5.3ms preprocess, 140.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.9ms\n","Speed: 5.4ms preprocess, 139.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.8ms\n","Speed: 5.2ms preprocess, 139.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.7ms\n","Speed: 4.8ms preprocess, 143.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 150.2ms\n","Speed: 4.6ms preprocess, 150.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.8ms\n","Speed: 4.7ms preprocess, 138.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 136.4ms\n","Speed: 4.6ms preprocess, 136.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.6ms\n","Speed: 4.6ms preprocess, 145.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 152.1ms\n","Speed: 5.7ms preprocess, 152.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.4ms\n","Speed: 4.9ms preprocess, 145.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.4ms\n","Speed: 5.8ms preprocess, 146.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 153.8ms\n","Speed: 6.1ms preprocess, 153.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.0ms\n","Speed: 5.0ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.9ms\n","Speed: 4.2ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.8ms\n","Speed: 5.3ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.6ms\n","Speed: 5.2ms preprocess, 137.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.9ms\n","Speed: 5.3ms preprocess, 141.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 159.1ms\n","Speed: 4.3ms preprocess, 159.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.3ms\n","Speed: 4.9ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.6ms\n","Speed: 4.3ms preprocess, 143.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.8ms\n","Speed: 5.0ms preprocess, 139.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.2ms\n","Speed: 4.4ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.5ms\n","Speed: 6.5ms preprocess, 144.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.4ms\n","Speed: 5.1ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 155.1ms\n","Speed: 4.9ms preprocess, 155.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.4ms\n","Speed: 4.2ms preprocess, 139.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.0ms\n","Speed: 4.6ms preprocess, 146.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.7ms\n","Speed: 4.8ms preprocess, 142.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.8ms\n","Speed: 5.2ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 150.4ms\n","Speed: 4.7ms preprocess, 150.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 157.8ms\n","Speed: 5.3ms preprocess, 157.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.1ms\n","Speed: 5.3ms preprocess, 139.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.1ms\n","Speed: 6.8ms preprocess, 143.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.5ms\n","Speed: 5.0ms preprocess, 141.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.1ms\n","Speed: 4.5ms preprocess, 141.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.5ms\n","Speed: 4.7ms preprocess, 145.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.8ms\n","Speed: 5.1ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 157.1ms\n","Speed: 4.5ms preprocess, 157.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 135.5ms\n","Speed: 5.3ms preprocess, 135.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.4ms\n","Speed: 4.9ms preprocess, 137.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.2ms\n","Speed: 4.6ms preprocess, 138.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 147.7ms\n","Speed: 5.2ms preprocess, 147.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.7ms\n","Speed: 5.2ms preprocess, 138.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 134.7ms\n","Speed: 4.7ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 147.2ms\n","Speed: 8.6ms preprocess, 147.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 136.5ms\n","Speed: 4.4ms preprocess, 136.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.3ms\n","Speed: 5.1ms preprocess, 137.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.3ms\n","Speed: 8.4ms preprocess, 140.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.9ms\n","Speed: 5.7ms preprocess, 141.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.3ms\n","Speed: 5.6ms preprocess, 141.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 152.0ms\n","Speed: 4.6ms preprocess, 152.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.0ms\n","Speed: 4.7ms preprocess, 146.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.4ms\n","Speed: 5.0ms preprocess, 138.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.6ms\n","Speed: 4.5ms preprocess, 137.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.8ms\n","Speed: 5.2ms preprocess, 144.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.8ms\n","Speed: 4.3ms preprocess, 137.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.9ms\n","Speed: 4.1ms preprocess, 144.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 158.7ms\n","Speed: 4.7ms preprocess, 158.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.5ms\n","Speed: 5.1ms preprocess, 140.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.5ms\n","Speed: 4.9ms preprocess, 137.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 177.8ms\n","Speed: 4.8ms preprocess, 177.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 222.7ms\n","Speed: 6.4ms preprocess, 222.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 218.3ms\n","Speed: 6.8ms preprocess, 218.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.3ms\n","Speed: 5.2ms preprocess, 212.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.7ms\n","Speed: 8.4ms preprocess, 212.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 220.9ms\n","Speed: 5.2ms preprocess, 220.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 218.9ms\n","Speed: 7.1ms preprocess, 218.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 228.2ms\n","Speed: 5.0ms preprocess, 228.2ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 210.4ms\n","Speed: 5.0ms preprocess, 210.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.6ms\n","Speed: 5.0ms preprocess, 212.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 208.0ms\n","Speed: 4.8ms preprocess, 208.0ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 206.2ms\n","Speed: 5.4ms preprocess, 206.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 219.1ms\n","Speed: 5.0ms preprocess, 219.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 215.1ms\n","Speed: 5.2ms preprocess, 215.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 219.7ms\n","Speed: 6.7ms preprocess, 219.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 221.1ms\n","Speed: 5.0ms preprocess, 221.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 223.4ms\n","Speed: 5.4ms preprocess, 223.4ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 214.6ms\n","Speed: 5.2ms preprocess, 214.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 148.1ms\n","Speed: 5.0ms preprocess, 148.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.5ms\n","Speed: 5.4ms preprocess, 143.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.5ms\n","Speed: 4.4ms preprocess, 137.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.0ms\n","Speed: 4.9ms preprocess, 142.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.7ms\n","Speed: 4.9ms preprocess, 141.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 155.3ms\n","Speed: 4.3ms preprocess, 155.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.5ms\n","Speed: 4.8ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.8ms\n","Speed: 4.7ms preprocess, 146.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.5ms\n","Speed: 5.0ms preprocess, 140.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.4ms\n","Speed: 5.5ms preprocess, 137.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 136.8ms\n","Speed: 4.4ms preprocess, 136.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 148.4ms\n","Speed: 4.5ms preprocess, 148.4ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.8ms\n","Speed: 5.6ms preprocess, 144.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.7ms\n","Speed: 6.9ms preprocess, 140.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.0ms\n","Speed: 5.0ms preprocess, 143.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.3ms\n","Speed: 4.5ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.9ms\n","Speed: 5.0ms preprocess, 142.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.2ms\n","Speed: 4.9ms preprocess, 140.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 158.0ms\n","Speed: 4.5ms preprocess, 158.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 150.8ms\n","Speed: 5.1ms preprocess, 150.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.5ms\n","Speed: 5.1ms preprocess, 141.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.8ms\n","Speed: 4.9ms preprocess, 140.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.6ms\n","Speed: 4.9ms preprocess, 144.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.0ms\n","Speed: 5.0ms preprocess, 143.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.1ms\n","Speed: 4.6ms preprocess, 146.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 153.4ms\n","Speed: 9.0ms preprocess, 153.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.4ms\n","Speed: 5.1ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.2ms\n","Speed: 4.5ms preprocess, 140.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.4ms\n","Speed: 5.1ms preprocess, 144.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 134.2ms\n","Speed: 4.7ms preprocess, 134.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.0ms\n","Speed: 5.2ms preprocess, 142.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 161.6ms\n","Speed: 7.2ms preprocess, 161.6ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.1ms\n","Speed: 4.5ms preprocess, 142.1ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.7ms\n","Speed: 5.3ms preprocess, 141.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 136.9ms\n","Speed: 4.8ms preprocess, 136.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.2ms\n","Speed: 4.6ms preprocess, 143.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.2ms\n","Speed: 4.9ms preprocess, 140.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.6ms\n","Speed: 5.4ms preprocess, 146.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 166.1ms\n","Speed: 5.0ms preprocess, 166.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.2ms\n","Speed: 4.9ms preprocess, 145.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.6ms\n","Speed: 4.8ms preprocess, 138.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.8ms\n","Speed: 4.5ms preprocess, 143.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 134.7ms\n","Speed: 5.3ms preprocess, 134.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.3ms\n","Speed: 4.6ms preprocess, 145.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 155.5ms\n","Speed: 4.2ms preprocess, 155.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.6ms\n","Speed: 5.8ms preprocess, 141.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.1ms\n","Speed: 5.0ms preprocess, 141.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.0ms\n","Speed: 4.0ms preprocess, 141.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.4ms\n","Speed: 5.4ms preprocess, 139.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.1ms\n","Speed: 4.8ms preprocess, 139.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.4ms\n","Speed: 6.8ms preprocess, 140.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 156.3ms\n","Speed: 5.1ms preprocess, 156.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.4ms\n","Speed: 5.2ms preprocess, 141.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.1ms\n","Speed: 4.9ms preprocess, 140.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.5ms\n","Speed: 5.1ms preprocess, 142.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.8ms\n","Speed: 4.5ms preprocess, 137.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.7ms\n","Speed: 6.1ms preprocess, 141.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.1ms\n","Speed: 5.0ms preprocess, 144.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 147.4ms\n","Speed: 9.4ms preprocess, 147.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 137.3ms\n","Speed: 4.9ms preprocess, 137.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.5ms\n","Speed: 4.6ms preprocess, 143.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.4ms\n","Speed: 5.0ms preprocess, 138.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.4ms\n","Speed: 4.8ms preprocess, 141.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 214.1ms\n","Speed: 4.5ms preprocess, 214.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 221.9ms\n","Speed: 5.9ms preprocess, 221.9ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 216.8ms\n","Speed: 5.2ms preprocess, 216.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 216.4ms\n","Speed: 5.1ms preprocess, 216.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 219.8ms\n","Speed: 5.2ms preprocess, 219.8ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 242.4ms\n","Speed: 5.0ms preprocess, 242.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 223.4ms\n","Speed: 7.5ms preprocess, 223.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 212.9ms\n","Speed: 4.8ms preprocess, 212.9ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 215.9ms\n","Speed: 4.8ms preprocess, 215.9ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 211.2ms\n","Speed: 5.1ms preprocess, 211.2ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 214.1ms\n","Speed: 5.2ms preprocess, 214.1ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 207.3ms\n","Speed: 4.8ms preprocess, 207.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 210.4ms\n","Speed: 5.1ms preprocess, 210.4ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 221.0ms\n","Speed: 5.1ms preprocess, 221.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 222.2ms\n","Speed: 5.0ms preprocess, 222.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 229.7ms\n","Speed: 5.0ms preprocess, 229.7ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 218.1ms\n","Speed: 4.9ms preprocess, 218.1ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 203.3ms\n","Speed: 5.1ms preprocess, 203.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.9ms\n","Speed: 4.6ms preprocess, 140.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.2ms\n","Speed: 4.8ms preprocess, 141.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 161.6ms\n","Speed: 3.8ms preprocess, 161.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 136.1ms\n","Speed: 4.3ms preprocess, 136.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.1ms\n","Speed: 6.1ms preprocess, 146.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 152.2ms\n","Speed: 5.3ms preprocess, 152.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.3ms\n","Speed: 6.4ms preprocess, 142.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.1ms\n","Speed: 4.7ms preprocess, 140.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.6ms\n","Speed: 5.2ms preprocess, 142.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 158.1ms\n","Speed: 5.3ms preprocess, 158.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.3ms\n","Speed: 5.5ms preprocess, 139.3ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.7ms\n","Speed: 5.1ms preprocess, 144.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.9ms\n","Speed: 5.2ms preprocess, 142.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.4ms\n","Speed: 6.4ms preprocess, 142.4ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.9ms\n","Speed: 5.6ms preprocess, 144.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 160.0ms\n","Speed: 5.7ms preprocess, 160.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.8ms\n","Speed: 6.1ms preprocess, 138.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 145.7ms\n","Speed: 5.3ms preprocess, 145.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.3ms\n","Speed: 5.5ms preprocess, 139.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.4ms\n","Speed: 5.2ms preprocess, 144.4ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.8ms\n","Speed: 4.8ms preprocess, 140.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 143.3ms\n","Speed: 4.6ms preprocess, 143.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 160.2ms\n","Speed: 4.2ms preprocess, 160.2ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.8ms\n","Speed: 5.2ms preprocess, 139.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 157.2ms\n","Speed: 5.4ms preprocess, 157.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.8ms\n","Speed: 4.7ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.5ms\n","Speed: 4.1ms preprocess, 139.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 141.8ms\n","Speed: 4.7ms preprocess, 141.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 156.6ms\n","Speed: 5.0ms preprocess, 156.6ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 140.3ms\n","Speed: 4.6ms preprocess, 140.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.9ms\n","Speed: 5.0ms preprocess, 138.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.8ms\n","Speed: 5.3ms preprocess, 142.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.9ms\n","Speed: 7.5ms preprocess, 142.9ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 138.3ms\n","Speed: 4.7ms preprocess, 138.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 144.8ms\n","Speed: 5.1ms preprocess, 144.8ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 154.1ms\n","Speed: 4.6ms preprocess, 154.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 142.7ms\n","Speed: 5.1ms preprocess, 142.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 146.2ms\n","Speed: 5.3ms preprocess, 146.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 135.2ms\n","Speed: 6.2ms preprocess, 135.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 139.0ms\n","Speed: 6.5ms preprocess, 139.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","\n","0: 384x640 1 person, 148.5ms\n","Speed: 5.3ms preprocess, 148.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n","✅ 완료: csv 저장됨\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"SUMom6pGnsK4"},"execution_count":null,"outputs":[]}]}